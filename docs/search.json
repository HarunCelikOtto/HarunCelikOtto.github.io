[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Harun Celik",
    "section": "",
    "text": "I’m a PhD student in History trying to do cool things with historical maps. Stick around to see the progress I try to make :)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Historical Mapping",
    "section": "",
    "text": "Edge Detection\n\n\n\n\n\n\n\nEdge Detection\n\n\nTemplate Matching\n\n\nPython\n\n\nSkimage\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 10, 2023\n\n\nHarun Celik\n\n\n\n\n\n\n  \n\n\n\n\nDigitizing A Historical Map [Image Processing]\n\n\n\n\n\n\n\nClassification\n\n\nR\n\n\nArcGIS\n\n\nPython\n\n\nSegmentation\n\n\n\n\n\n\n\n\n\n\n\nApr 15, 2023\n\n\nHarun Celik\n\n\n\n\n\n\n  \n\n\n\n\nDigitizing A Historical Map [Classifications]\n\n\n\n\n\n\n\nClassification\n\n\nR\n\n\nArcGIS\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nApr 3, 2023\n\n\nHarun Celik\n\n\n\n\n\n\n  \n\n\n\n\nHow to Un-Break R with Arcpy in ArcGIS Pro\n\n\n\n\n\n\n\nReticulate\n\n\nArcGIS\n\n\nArcpy\n\n\nR\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nMar 23, 2023\n\n\nHarun Celik\n\n\n\n\n\n\n  \n\n\n\n\nPackages in Development\n\n\n\n\n\n\n\nR\n\n\nArcGIS\n\n\nPython\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2023\n\n\nHarun Celik\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Edge-Detection-Image-Templates/Edge-Detection.html",
    "href": "posts/Edge-Detection-Image-Templates/Edge-Detection.html",
    "title": "Edge Detection",
    "section": "",
    "text": "I wanted to start by announcing that the small pause on uploads for the blog were due to my involvement in the DSPG program at Iowa State University for the summer. If there is interest on details for the program, one can check out the main page, the DSPG team blogs about each of the team’s work, or my personal blog where I document my work and goals working in the DSPG program for the summer of 2023.\nThis blog is a slight change of pace to the previous ones in that we are putting aside the spatial component and instead exploring how two different techniques in image processing apply to our historical map. The two techniques that will be discussed in the following two blogs are edge detection and template matching. To demonstrate the use cases, I’ll be working with the scikit-image library for python dedicated to image processing. We’ll focus on edge detection for this blog.\nThe following modules are required to run the functions we need for image processing.\n\n# Python\nfrom skimage import io, filters\nfrom skimage.color import rgb2gray\nfrom matplotlib import pyplot as plt\nfrom skimage.feature import match_template\n\nNext we can go ahead and import the images we will be conducting the processing on.\n\n# Python\n\n# Importing Images\nimg = io.imread(\"Images/Postal_Buchanan_Route.png\")[:,:,:3] ## ORIGINAL IMG\ntrain_snip = io.imread(\"Images/TRAIN_Route.png\")[:,:,:3] ## TRAIN LINE\ncity_snip = io.imread(\"Images/City.png\")[:,:,:3] ## CITY POINT\n\nAs their name suggests, edge detection models work to find the edges of objects in images. Determining the contours and edges of objects on two dimensional planes is an easy task for the human visual system but not so much for machines which see the images as matrices of numerical values.\nAs humans, here is what we see when we want to view the image we loaded in called train_snip.\n\n# R\n\n# load image viewing library\nlibrary(imager)\n\n# Plot image\nim &lt;- load.image(file = \"Images/TRAIN_Route.png\")\nplot(im,axes = FALSE)\n\n\n\n\nAs we can see, its a snippet of one of the rail track features in our map. What the computer sees instead is a series of three arrays to represent the Red, Green, and Blue values across the image. The code below tells us that this image is 116 pixels in length, 39 pixels in width and has three channels which are RGB.\n\n#Python\n\ntrain_snip.shape\n\n(116, 39, 3)\n\n\nThe multiple channels for color add additional mathematical complexity to the picture so most edge detection models instead opt to use gray scale renders of images to reduce that complexity. Edge detection models will commonly use a sliding window called a kernel which slides across the image and recalculates the values of pixels on the original image by a set of values determined for the kernel. I think that this is best explained interactively and DeepLizard has a fantastic tool that demonstrates how this process works.\nLet’s convert the two snippets we have from the map in RGB to their gray scale forms. When we call the shape method we see that we no longer have the ‘3’ at the third slot, meaning that these images are now only a single channel.\n\n# Python\n\ngray_train = rgb2gray(train_snip)\ngray_city = rgb2gray(city_snip)\n\ngray_train.shape\n\n(116, 39)\n\ngray_city.shape\n\n(49, 60)\n\n\nThere are a number of different edge detection models and important differences for the output of the models are based off of how they recognize the edges of features which have more rotational variance.\nLet’s see how some of the models perform on our small train picture. Here are the different kinds of edge detection models we want to see processed. Scikit-Image provides functions on;\n\nRobert’s Edge Detection\nSobel’s Edge Detection\nScharr’s Edge Detection\nPreewitt’s Edge Detection\nFarid’s Edge Detection\n\n\n# Python\n\n### Edge Detection on Train\n\n#### Roberts Edge Detection\nedge_roberts = filters.roberts(gray_train)\n#### Sobel Edge Detection\nedge_sobel = filters.sobel(gray_train)\n#### Scharr Edge Detection\nedge_scharr = filters.scharr(gray_train)\n#### Prewitt Edge Detection\nedge_prewitt = filters.prewitt(gray_train)\n#### Farid Transform\nedge_farid = filters.farid(gray_train)\n\nNow to plot them next to each other so we can see a comparison of how the image turned out.\n\nfig2 = plt.figure(figsize=(10,7))\n                  \nrows = 2\ncolumns = 3                 \n\nfig2.add_subplot(rows,columns,1)\n\nplt.imshow(edge_roberts)\nplt.axis(\"off\")\nplt.title(\"Roberts\")\n\nfig2.add_subplot(rows,columns,2)\n\nplt.imshow(edge_sobel)\nplt.axis(\"off\")\nplt.title(\"Sobel\")\n\nfig2.add_subplot(rows,columns,3)\n\nplt.imshow(edge_scharr)\nplt.axis(\"off\")\nplt.title(\"Scharr\")\n\nfig2.add_subplot(rows,columns,4)\n\nplt.imshow(edge_prewitt)\nplt.axis(\"off\")\nplt.title(\"Scharr\")\n\nfig2.add_subplot(rows,columns,5)\n\nplt.imshow(edge_farid)\nplt.axis(\"off\")\nplt.title(\"Farid\")\n\nfig2.add_subplot(rows,columns,6)\n\nplt.imshow(train_snip)\nplt.axis(\"off\")\nplt.title(\"Original\")\n\nfig2.savefig(\"Train_Edges\", dpi=600)\n\n\n\n\nTrain Snippet Through Different Edge Detection Models\n\n\nWith the naked eye it looks like Sobel, Scharr, and Prewitt have similar outputs while Roberts and Farid produced values which had higher intensity values on different sections of the edges.\nWe can also do the same for an image snippet we have for the features on the map that identify cities. The following code chunk applies the same processing operations on those features.\n\n# Python\n\n### Edge Detection on City\n#### Roberts Edge Detection\nedge_roberts_city = filters.roberts(gray_city)\n#### Sobel Edge Detection\nedge_sobel_city = filters.sobel(gray_city)\n#### Scharr Edge Detection\nedge_scharr_city = filters.scharr(gray_city)\n#### Prewitt Edge Detection\nedge_prewitt_city = filters.prewitt(gray_city)\n#### Farid Transform\nedge_farid_city = filters.farid(gray_city)\n\nfig1 = plt.figure(figsize=(10,7))\n                  \nrows = 2\ncolumns = 3                 \n\nfig1.add_subplot(rows,columns,1)\n\nplt.imshow(edge_roberts_city)\nplt.axis(\"off\")\nplt.title(\"Roberts\")\n\nfig1.add_subplot(rows,columns,2)\n\nplt.imshow(edge_sobel_city)\nplt.axis(\"off\")\nplt.title(\"Sobel\")\n\nfig1.add_subplot(rows,columns,3)\n\nplt.imshow(edge_scharr_city)\nplt.axis(\"off\")\nplt.title(\"Scharr\")\n\nfig1.add_subplot(rows,columns,4)\n\nplt.imshow(edge_prewitt_city)\nplt.axis(\"off\")\nplt.title(\"Prewitt\")\n\nfig1.add_subplot(rows,columns,5)\n\nplt.imshow(edge_farid_city)\nplt.axis(\"off\")\nplt.title(\"Farid\")\n\nfig1.add_subplot(rows,columns,6)\n\nplt.imshow(city_snip)\nplt.axis(\"off\")\nplt.title(\"Original\")\n\nfig1.savefig(\"City_Edges\", dpi=600)\n\n\n\n\nCity Snippet Through Different Edge Detection Models\n\n\nThe city image has continuous features which rotate more than our train image so the differences in certain edge intensities are better reflected. All of the process do a pretty good job with detecting the edges of the lines in the image.\nNow that we have a sense of what these look like, let’s see what happens when run these on the complete image.\n\n# Python\n\n### Edge Detection for Complete Image\n#### Roberts Edge Detection\nedge_roberts_og = filters.roberts(gray_img)\n#### Sobel Edge Detection\nedge_sobel_og = filters.sobel(gray_img)\n#### Scharr Edge Detection\nedge_scharr_og = filters.scharr(gray_img)\n#### Prewitt Edge Detection\nedge_prewitt_og = filters.prewitt(gray_img)\n#### Farid Transform\nedge_farid_og = filters.farid(gray_img)\n\n# \nfig = plt.figure(figsize=(10,7))\n                  \nrows = 2\ncolumns = 3                 \n\nfig.add_subplot(rows,columns,1)\n\nplt.imshow(edge_roberts_og)\nplt.axis(\"off\")\nplt.title(\"Roberts\")\n\nfig.add_subplot(rows,columns,2)\n\nplt.imshow(edge_sobel_og)\nplt.axis(\"off\")\nplt.title(\"Sobel\")\n\nfig.add_subplot(rows,columns,3)\n\nplt.imshow(edge_scharr_og)\nplt.axis(\"off\")\nplt.title(\"Scharr\")\n\nfig.add_subplot(rows,columns,4)\n\nplt.imshow(edge_prewitt_og)\nplt.axis(\"off\")\nplt.title(\"Prewitt\")\n\nfig.add_subplot(rows,columns,5)\n\nplt.imshow(edge_farid_og)\nplt.axis(\"off\")\nplt.title(\"Farid\")\n\nfig.add_subplot(rows,columns,6)\n\nplt.imshow(img)\nplt.axis(\"off\")\nplt.title(\"Original\")\n\nfig.savefig(\"Complete_Edges\", dpi=600)\n\n\n\n\nThe Complete Raster Through Different Edge Detection Models\n\n\nLooking at the whole map, I think the differences in the intensity values for the different techniques becomes more apparent. The success of the detectors in being able to identify the edges could be fruitful in the process of creating masks for the image to separate the features from the background. This could be done by setting a threshold for intensity values so that only those which are bright (and detected as edges) get preserved. An additional purpose may be for the preservation of map features digitally, since the edges are recorded accurately and uniformly.\nFor the purposes of the Historical Mapping project, edge detection is a useful tool because it doesn’t require training data. In an effort to make a model which works with maps through unsupervised classification, edge detection can help to separate features of the map we want the classifier to avoid trying to classify. It’s exact usage remains to be seen, but for the purposes of unsupervised classification, edge detection remains a popular option. Next time, we’ll look at template matching to see how intensity values on the map change based on templates provided of the map features."
  },
  {
    "objectID": "posts/Map-Digitizing-Part-One/index.html",
    "href": "posts/Map-Digitizing-Part-One/index.html",
    "title": "Digitizing A Historical Map [Part One]",
    "section": "",
    "text": "In this entry, I want to showcase some of the opportunities that exist with working on scanned historical maps using some image processing and GIS tools. The scanned map that I will be working on is a section of the Postal Route Map of the United States. The map is titled Upper Part. Post Route Map of States of Illinois, Iowa and Missouri and dated to 1879. I’ve downloaded a georeferenced copy of this map through the David Rumsey Map Collection at Stanford. I have yet to find the complete map of the Post Routes but other portions of it can also be found in the Library of Congress."
  },
  {
    "objectID": "posts/Map-Digitizing-Part-One/index.html#loading-libraries",
    "href": "posts/Map-Digitizing-Part-One/index.html#loading-libraries",
    "title": "Digitizing A Historical Map [Part One]",
    "section": "Loading Libraries",
    "text": "Loading Libraries\nUntil I figure out how to share the actual clipped imagery files on the blog page, I’ll just assume the reader will want to see the code rather than execute it. Nevertheless, if you have raster images that you replace the paths for, all of the functionality should operate just fine. I am currently working to solve the dependencies of the aRcGeo package if you have access to ArcGIS Pro and also installed arcgisbinding to follow along.\n\nlibrary(sf)\nlibrary(aRcGeo)\nlibrary(raster)"
  },
  {
    "objectID": "posts/Map-Digitizing-Part-One/index.html#setting-paths-to-raster-files",
    "href": "posts/Map-Digitizing-Part-One/index.html#setting-paths-to-raster-files",
    "title": "Digitizing A Historical Map [Part One]",
    "section": "Setting Paths to Raster Files",
    "text": "Setting Paths to Raster Files\nIn order for the tests to run quicker, I’ve clipped two sections of the Upper Postal Routes Map to conduct our spatial analysis on. One of them surrounds the Des Moines area and the other in Buchanan, Iowa. I chose these two locations because together they contain most of the unique cartographic objects that exists throughout the complete map.\nWe’ll start by creating a path to these files so that we can use them for conversion later. The file format that I downloaded the images in are .tif files.\n\ntrim_path &lt;- file.path(\"..\", \"GIS_DATA\", \"Maps\", \"Trims\")\n\nDes_Moines_Postal_Route_tif &lt;- file.path(trim_path, \"Des_Moines_Postal_Route.tif\")\nBuchanan_Postal_Route_tif &lt;- file.path(trim_path, \"Postal_Routes_Selection.tif\")"
  },
  {
    "objectID": "posts/Map-Digitizing-Part-One/index.html#load-des-moines-postal-route-raster-image",
    "href": "posts/Map-Digitizing-Part-One/index.html#load-des-moines-postal-route-raster-image",
    "title": "Digitizing A Historical Map [Part One]",
    "section": "Load Des Moines Postal Route Raster Image",
    "text": "Load Des Moines Postal Route Raster Image\nOur Des Moines Postal Route Raster is composed of 4 bands. Here we can assume that we are getting the Red, Green, and Blue color bands as well as an additional band we can use as Near Infrared.\n\nDMoines_Raster &lt;- brick(Des_Moines_Postal_Route_tif) \n\n# Display Raster Information\nDMoines_Raster\n\nclass      : RasterBrick \ndimensions : 1984, 2928, 5809152, 4  (nrow, ncol, ncell, nlayers)\nresolution : 36.04464, 36.04464  (x, y)\nextent     : -10484535, -10378996, 5060635, 5132148  (xmin, xmax, ymin, ymax)\ncrs        : +proj=merc +a=6378137 +b=6378137 +lat_ts=0 +lon_0=0 +x_0=0 +y_0=0 +k=1 +units=m +nadgrids=@null +wktext +no_defs \nsource     : Des_Moines_Postal_Route.tif \nnames      : Des_Moines_Postal_Route_1, Des_Moines_Postal_Route_2, Des_Moines_Postal_Route_3, Des_Moines_Postal_Route_4 \nmin values :                         0,                         0,                         0,                         0 \nmax values :                       255,                       255,                       255,                       255"
  },
  {
    "objectID": "posts/Map-Digitizing-Part-One/index.html#load-buchanan-postal-route-raster-image",
    "href": "posts/Map-Digitizing-Part-One/index.html#load-buchanan-postal-route-raster-image",
    "title": "Digitizing A Historical Map [Part One]",
    "section": "Load Buchanan Postal Route Raster Image",
    "text": "Load Buchanan Postal Route Raster Image\nSince the images are from the same raster, this clip also has the same number of bands.\n\nBuchanan_Raster &lt;- brick(Buchanan_Postal_Route_tif)\n\n# Display Buchanan Raster Information\nBuchanan_Raster\n\nclass      : RasterBrick \ndimensions : 1412, 2120, 2993440, 4  (nrow, ncol, ncell, nlayers)\nresolution : 36.04464, 36.04464  (x, y)\nextent     : -10284415, -10208000, 5222656, 5273551  (xmin, xmax, ymin, ymax)\ncrs        : +proj=merc +a=6378137 +b=6378137 +lat_ts=0 +lon_0=0 +x_0=0 +y_0=0 +k=1 +units=m +nadgrids=@null +wktext +no_defs \nsource     : Postal_Routes_Selection.tif \nnames      : Postal_Routes_Selection_1, Postal_Routes_Selection_2, Postal_Routes_Selection_3, Postal_Routes_Selection_4 \nmin values :                        31,                        13,                         0,                       255 \nmax values :                       255,                       242,                       234,                       255"
  },
  {
    "objectID": "posts/Map-Digitizing-Part-One/index.html#displaying-the-maps",
    "href": "posts/Map-Digitizing-Part-One/index.html#displaying-the-maps",
    "title": "Digitizing A Historical Map [Part One]",
    "section": "Displaying the Maps",
    "text": "Displaying the Maps\nWe can take a quick look at an RGB render of the rasters with Natural Color, giving us the color scheme we are used to seeing the maps with our eyes.\n\nplotRGB(DMoines_Raster)\n\n\n\n\nIf we wanted the image in a rearranged RGB render, like Color Infrared, we would replace the order of our bands. In the case of Color Infrared, the first red band would be replaced with band 4 to get the following result.\n\nplotRGB(DMoines_Raster, r=4)\n\n\n\n\nThe plot function will show us all of the bands individually though the way this is represented by default is a little unintuitive because of the way the color schemes work. We can read these plots as, _1 represents the Red band, _2 the Blue, and so on.\n\nplot(DMoines_Raster)"
  },
  {
    "objectID": "posts/Map-Digitizing-Part-One/index.html#preparing-images-for-processing",
    "href": "posts/Map-Digitizing-Part-One/index.html#preparing-images-for-processing",
    "title": "Digitizing A Historical Map [Part One]",
    "section": "Preparing Images for Processing",
    "text": "Preparing Images for Processing\nTo make our classification more successful, let’s look to see the kinds of problems we might be facing without any pre-processing on our image.\n\nplotRGB(Buchanan_Raster)\n\n\n\n\nWe want to use an ISO Clustering Unsupervised model for classification. At a simplified level, we are going to tell the the machine to look at pixels across this image and classify an x number of objects to digitize as it does so. What we are hoping for is that the classification will extract the same number of classes that we see as features on the map.\nBased on the complete elements of this particular map, we have 14 unique classes that we would like to identify.\nThe first two of these classes are information about the “empty” map spaces. It’s important to try and identify these areas clearly so that we can understand how well the clustering works in separating the features we want from these two classes. These are…\n\nMap Background\nMap Stitching\n\nThe remaining classes are the more intuitive features we would like to classify.\n\nMap Element Titles (i.e. for cities, the map, or numerical values)\nCircles indicating City Locations\nRail Tracks\nPostal Route (Yellow)\nPostal Route (Blue)\nPostal Route (Red)\nRivers (thicker)\nRivers (thinner)\nWater bodies\nMap Borders\nCounty Borders\nState Borders\n\nLet’s run the classification to see what happens."
  },
  {
    "objectID": "posts/Map-Digitizing-Part-One/index.html#running-first-set-of-classifications",
    "href": "posts/Map-Digitizing-Part-One/index.html#running-first-set-of-classifications",
    "title": "Digitizing A Historical Map [Part One]",
    "section": "Running First Set of Classifications",
    "text": "Running First Set of Classifications\nFirst we will need to initialize the connection to ArcGIS Pro and load the arcpy module. We also need to check out the Spatial Analyst extension.\n\naRcGeo::init_arcpy(conda_env = \"arcgispro-py3-DeepLearning\")\narcpy$CheckExtension(\"Spatial\")\narcpy$env$workspace = getwd()\n\nIn the Buchanan example we don’t have all the 14 classification features we need but we can keep the number high and ask for 10 instead.\n\n# Run Classification\nBuchanan_Classified_10 &lt;- arcpy$sa$IsoClusterUnsupervisedClassification(in_raster_bands = Buchanan_Postal_Route_tif, Number_of_classes = 10)\n\nHere’s our output in an ArcGIS screenshot.\n\n\n\nClassification of Buchanan Clip with 10 Features\n\n\nHere’s our original for reference.\n\nplotRGB(Buchanan_Raster)\n\n\n\n\nAs we can see, the output is extremely messy. The classifier has identified classes that we aren’t totally interested in. This is clear in the background areas of the map where certain blemishes get classified as different features. While that’s really cool, our intention is to actually classify the map background as a single feature.\nWe can try classification again with less features hoping to get a less muddy picture.\n\n# Run Classification\nBuchanan_Classified_5 &lt;- arcpy$sa$IsoClusterUnsupervisedClassification(in_raster_bands = Buchanan_Postal_Route_tif, Number_of_classes = 5)\n\nHere’s our new classification with only 5 classes.\n\n\n\nClassification of Buchanan Clip with 5 Features\n\n\nThe results are significantly clearer and we can tell that the classifier did a good job of outlining the different rail lines and postal lines as well. We can also tell that the classifier also highlighted some background map features for us instead of differentiating between the different postal route colors.\nThis is not perfect, but we are definitely closer to the digitized output that we would like to reach. In the next blog, I will introduce some methods for how we can avoid classifying those background marks in the hopes of classifying the postal routes instead.\nTO BE CONTINUED…"
  },
  {
    "objectID": "posts/Map-Digitizing-Part-Two/index.html",
    "href": "posts/Map-Digitizing-Part-Two/index.html",
    "title": "Digitizing A Historical Map [Image Processing]",
    "section": "",
    "text": "In the previous blog, we ran a classification function without using any pre-processing on the image. The results were fairly impressive but had some imperfections for our use case that is going to be discussed in this blog."
  },
  {
    "objectID": "posts/Map-Digitizing-Part-Two/index.html#introduction",
    "href": "posts/Map-Digitizing-Part-Two/index.html#introduction",
    "title": "Digitizing A Historical Map [Image Processing]",
    "section": "",
    "text": "In the previous blog, we ran a classification function without using any pre-processing on the image. The results were fairly impressive but had some imperfections for our use case that is going to be discussed in this blog."
  },
  {
    "objectID": "posts/Map-Digitizing-Part-Two/index.html#processing-extent",
    "href": "posts/Map-Digitizing-Part-Two/index.html#processing-extent",
    "title": "Digitizing A Historical Map [Image Processing]",
    "section": "Processing Extent",
    "text": "Processing Extent\n\n\n\nISO Cluster Unsupervised Five Classes\n\n\nTo retrieve the output above we set our classification to 5 classes but were only returned 3 because the classifier didn’t find enough proximity between the differing features. To fix this, a potential solution is to run the classifier on the complete raster and to set the processing output to the desired clipped area like the one we have here with Buchanan, Iowa. Doing this ensures that classifications are established based on features from the complete map raster and assigned across any selected area. Otherwise the classifier may fail to classify objects which are less common in other parts of the raster.\nWe can see a discernible difference if we run the classification on the whole raster and set the processing extent on Buchanan, Iowa rather on only running on the clipped area.\nLet’s fist load our libraries\n\nlibrary(aRcGeo)\nlibrary(arcgisbinding)\nlibrary(reticulate)\n\nlibrary(sf)\nlibrary(raster)\nlibrary(tidyverse)\n\nWe will first establish paths to our raster files like last time. This time, I am also adding a path to the full postal route map.\n\nsetwd(\"../GIS_DATA/Maps/\")\n\n# Paths to rasters\nRaster_Paths &lt;- file.path(getwd())\n\ntrim_path &lt;- file.path(Raster_Paths, \"Trims\")\n\n# The full map\nUpper_Postal_Route_ALL_tif &lt;- file.path(Raster_Paths, \"Upper_Part_Post_Route_Map_of_States_of_Illinois_Iowa_and_Missouri.tif\")\n\n# The clipped maps\nDes_Moines_Postal_Route_tif &lt;- file.path(trim_path, \"Des_Moines_Postal_Route.tif\")\nBuchanan_Postal_Route_tif &lt;- file.path(trim_path, \"Postal_Routes_Selection.tif\")\n\nWe then need to initialize a connection and set our workspace to the geodatabase.\n\naRcGeo::init_arcpy(conda_env = \"arcgispro-py3-DeepLearning\")\narcpy$CheckExtension(\"Spatial\")\narcpy$env$workspace = file.path(getwd(), \"HistoricalMapMachineLearning.gdb\")\n\nWe will also set our processing extent to the postal route clip including Buchanan, Iowa. Here I am using a raster object inside of the database with the same extents.\n\narcpy$env$extent &lt;- \"Stretch_Postal_IsoClusterUns\"\n\nMost arcpy functions will only take absolute paths so we have to be careful about the path we set for our in_raster_bands argument.\n\nUpper_Postal_Route_ALL_tif &lt;- stringr::str_replace_all(Upper_Postal_Route_ALL_tif, \"/\", \"\\\\\\\\\")\n\nBuchanan_Classified_Five &lt;- arcpy$sa$IsoClusterUnsupervisedClassification(in_raster_bands = Upper_Postal_Route_ALL_tif, Number_of_classes = 5)\n\nBuchanan_Classified_Five$save(\"Buchanan_Classified_Five\")\n\nWe can see in the results that we now have more classes in our clipped raster and can be more confident that other areas on the map will also be classified more uniformly.\n\n\n\nFive Classifications on Buchanan through Set Extent"
  },
  {
    "objectID": "posts/Map-Digitizing-Part-Two/index.html#classification-clutters",
    "href": "posts/Map-Digitizing-Part-Two/index.html#classification-clutters",
    "title": "Digitizing A Historical Map [Image Processing]",
    "section": "Classification Clutters",
    "text": "Classification Clutters\nIn the latter classified example (one with set extent), we saw that the classifier distinguished the linear features quite well, but features like the postal routes were not all classified as unique features. We have a classified blue and yellow postal route but no unique class for the red one. This isn’t an ideal classification output if we intend to run any spatial tests on the three separate postal routes.\n\nbrick(Buchanan_Postal_Route_tif) %&gt;%\n  plotRGB()\n\n\n\n\nAnother concern are the classified background patches of the map which we can see in a lighter color in the former example and in dark green in the latter one. While we might be able to ignore them by removing their classifications in a GIS program, increasing the number of desired classifications will only continue to mix parts of the background with features we would like to identify independently which is an obvious larger concern.\nOur test with the five classifications above partially verifies this. As we returned a higher class count, we didn’t necessarily get the features we wanted but rather features on the map that were closer as a class mathematically. The classifier found that background spots were closer together in pixel value than red colored routes. That’s why we only have two postal routes uniquley identified but even more of the background appearing as additional classes.\nAt this point, we can turn to working on processing the original image so that we are able to get a better classification for our purposes."
  },
  {
    "objectID": "posts/Map-Digitizing-Part-Two/index.html#image-stretch",
    "href": "posts/Map-Digitizing-Part-Two/index.html#image-stretch",
    "title": "Digitizing A Historical Map [Image Processing]",
    "section": "Image Stretch",
    "text": "Image Stretch\nOne way to remove those features is to use a stretch function. Help on the Arcgis Stretch function defines the functions as “[improving] the appearance of the data by spreading the pixel values along a histogram from the minimum and maximum values defined by their bit depth.” Without going into too much detail about the whole process, we can display the results of a high-filter min-max stretch to see how it affects our clipped extent.\n\narcpy$ia$Stretch(Buchanan_Postal_Route_tif, \"PercentClip\", min_percent = , max_percent = 85)\n\nThe resulting image is sharper and filters out a lot of the blotched pieces of the map background successfully. \n\n\n\nStretched Buchanan Clip\n\n\nWith this stretched image, the classifier does a better job of focusing on the features we are more interested in while removing those background pieces. We can see quite a difference when we overlay the previous classification with the new stretched one.\n\n\n\nDifference in Classification from Original to Stretch\n\n\nHere is the stretched classification in closer detail. Our goal of removing the background patterns has worked relatively well with a lesser portion of the darker blemishes making their appearance as a class. Another success is that we are getting an additional classification for the different postal routes though the classification is still not entirely accurate. The red and blue routes from our original map are mixed in a single classification. Perhaps requesting a higher classification output could help with that but unfortunately, the classifier only finds 5 different classes with the stretched map.\nOur solution may be to take a step back and process the image further.\n\n\n\nClassification on Buchanan Stretch"
  },
  {
    "objectID": "posts/Map-Digitizing-Part-Two/index.html#image-segmentation",
    "href": "posts/Map-Digitizing-Part-Two/index.html#image-segmentation",
    "title": "Digitizing A Historical Map [Image Processing]",
    "section": "Image Segmentation",
    "text": "Image Segmentation\nWe need to return more classes and we are also interested in further getting rid of the patches that still appear in the background. Stretching the image further potentially risks losing features on the map that are not as boldly drawn. The county lines or creek features which thin out are good examples of the information we may accidentally remove with more stretching.\nUsing our stretched image, we have the option to use an image segmentation model to segment features on the map based on the adjustment of average pixel values in an area to their closest values. The output of a high spatial and low spectral segmentation model looks like this.\n\n\n\nSegmented Buchanan Raster\n\n\nSome advantages of the segmentation is that we are able to get rid of a significant portion of the background pieces of the map. This even includes the stitching that we could see in the original and previous classified images. Our features are segmented well but it is at the cost of reducing the legibility of the textual features on the map. The trade-off is one that has to be considered if those particular features are desired features to be digitized from the map.\nIf we are happy with the result we can run a classification on this model and see how that performs.\n\n\n\nSegmented Classification on Buchanan\n\n\nIn the classification output above, I’ve removed a lot of the background classifications so we can see the underlying tile map. There are major improvements. All unique postal features are classified properly and we have almost none of the blemishes from the background of the map bleeding into the features.\nWe are still working with color values and its normal for the classifier to confuse colors that are on the edges of our features, since they have different values to the inner pixels. It may be a little difficult to see but some of the the Segmented Classification map features are surrounded by the red classification. This isn’t a major complication but it will be something we need to work on in order to get better features extracted for when we want to conduct our spatial analysis. This is something I will be touching on in the following blog.\nFor now, let’s look at the fruits of our labor by adding a layer containing all current rail line features provided by the Iowa Department of Transportation (DOT) (updated last on November 22, 2022) and see how it compares to the lines of our historical map.\n\n\n\nClassified Buchanan with Current Railroads\n\n\nWe can see just from this example we’ve been working on that the lower rail line currently operated by the Canadian National Railways is probably the same rail track documented in our historical map. The Iowa Northern Railway moving northeast and southwest however is not represented in our historical map. Interestingly, we see that there is a northern line on the historical map which doesn’t correspond to any current rail line that the Iowa DOT data provides. With the information that our map documents rail lines pre-1879, we can answer some interesting questions about the development of railways in Iowa.\nThere are reasons as to why the rail lines don’t exactly overlap with one another but I will also dedicate a blog in explaining how we can overcome differences like this so that we can conduct our historical and spatial analysis.\nTO BE CONTINUED"
  },
  {
    "objectID": "posts/Project-Ideas/index.html",
    "href": "posts/Project-Ideas/index.html",
    "title": "Packages in Development",
    "section": "",
    "text": "Below are descriptions of packages under development that I am an author on. Overall their purpose is to help aid humanists and social scientists in working with spatial and tabular data. As you can tell, I like naming these packages based on popular R package conventions even if the projects aren’t exclusively written for R."
  },
  {
    "objectID": "posts/Project-Ideas/index.html#arcgeo",
    "href": "posts/Project-Ideas/index.html#arcgeo",
    "title": "Packages in Development",
    "section": "aRcGeo",
    "text": "aRcGeo\nInitializing an ArcGIS Pro arcpy environment in your R session will now take a single function with the help of aRcGeo. The goal of this package is to help streamline the process of setting up the right python environment as well as importing the arcpy module using reticulate and arcgisbinding to run spatial analysis in R using the ArcGIS family of spatial software. Being able to use arcpy in an R session means that your analysis can also benefit from the growing number of r-spatial packages.\nThe package is currently released and available through HarunCelikOtto/aRcGeo."
  },
  {
    "objectID": "posts/Project-Ideas/index.html#carte",
    "href": "posts/Project-Ideas/index.html#carte",
    "title": "Packages in Development",
    "section": "CaRte",
    "text": "CaRte\nCaRte is a package served as a toolbox for common pre-processing techniques to help with scanned cartographic analysis. The purpose of CaRte is to supply the digital researcher a set of common image pre-processing tools to aid the automation process of digitizing historical maps."
  },
  {
    "objectID": "posts/Project-Ideas/index.html#georfrncr",
    "href": "posts/Project-Ideas/index.html#georfrncr",
    "title": "Packages in Development",
    "section": "GeoRfrncr",
    "text": "GeoRfrncr\nSince automatic georeferencing is still uncommon in GIS software, the GeoRfrncr package is designed to help automate the process of georeferencing scans for historical maps. The package will rely on scanned and pre-processed maps that can be produced using the CaRte package. With less time spent georeferencing, more time is available towards working on the spatial analysis of digitized maps."
  },
  {
    "objectID": "posts/Project-Ideas/index.html#tabulr",
    "href": "posts/Project-Ideas/index.html#tabulr",
    "title": "Packages in Development",
    "section": "TabulR",
    "text": "TabulR\nThis package is inspired as an additional functionality to the tabula-java package used to extract tabular data from PDFs. The primary goal of this package is to have an open source tool which can extract tabular data used in scholarly publications. The availability of data extracted from printed scholarship can help researchers conduct easier analysis by digital means."
  },
  {
    "objectID": "posts/Project-Ideas/index.html#hsus-api",
    "href": "posts/Project-Ideas/index.html#hsus-api",
    "title": "Packages in Development",
    "section": "HSUS API",
    "text": "HSUS API\nThis package is an API that can connect to the tabulated data collected in the Historical Statistics of the United States Millennial Edition Online. The API will require a key for access to any individual or organization which has a subscription."
  },
  {
    "objectID": "posts/Unbreaking-R-Arcpy/index.html",
    "href": "posts/Unbreaking-R-Arcpy/index.html",
    "title": "How to Un-Break R with Arcpy in ArcGIS Pro",
    "section": "",
    "text": "Less than a week ago, I had the pleasure of running into a very annoying problem trying to load the arcpy module for python in R using reticulate. I found that after setting up the right python environments to work with arcpy, I could load in most of the modules except for those in the arc_ family.\nI did not find information addressing this concern directly so I wanted to document this behavior for anyone else trying to use arcpy in R."
  },
  {
    "objectID": "posts/Unbreaking-R-Arcpy/index.html#introduction",
    "href": "posts/Unbreaking-R-Arcpy/index.html#introduction",
    "title": "How to Un-Break R with Arcpy in ArcGIS Pro",
    "section": "",
    "text": "Less than a week ago, I had the pleasure of running into a very annoying problem trying to load the arcpy module for python in R using reticulate. I found that after setting up the right python environments to work with arcpy, I could load in most of the modules except for those in the arc_ family.\nI did not find information addressing this concern directly so I wanted to document this behavior for anyone else trying to use arcpy in R."
  },
  {
    "objectID": "posts/Unbreaking-R-Arcpy/index.html#requirements",
    "href": "posts/Unbreaking-R-Arcpy/index.html#requirements",
    "title": "How to Un-Break R with Arcpy in ArcGIS Pro",
    "section": "Requirements",
    "text": "Requirements\n\nArcGIS Pro 1.1 or later\nR Statistical Computing Software, 3.5 or later\n64-bit version required for ArcGIS Pro (Note: the installer installs both by default).\nInstallation of the arcgisbinding package for R\nClone of the arcgispro-py3 python environment"
  },
  {
    "objectID": "posts/Unbreaking-R-Arcpy/index.html#establishing-a-connection-to-arcgis",
    "href": "posts/Unbreaking-R-Arcpy/index.html#establishing-a-connection-to-arcgis",
    "title": "How to Un-Break R with Arcpy in ArcGIS Pro",
    "section": "Establishing a Connection to ArcGIS",
    "text": "Establishing a Connection to ArcGIS\nThe issue seems to arise out of licensing requirements from the arcpy module. This is the assumption because modules like arcgis and other non-licensing required modules can be imported successfully. To be able to check out the license for ArcGIS in R, we will need to have the R-ArcGIS bridge installed.\nOnce r-bridge is installed and a directory is set within the geoprocessing options of ArcGIS we can call the library for arcgisbinding to use the function arc.check_product().\n\nlibrary(arcgisbinding)\n\n*** Please call arc.check_product() to define a desktop license.\n\narc.check_product()\n\nproduct: ArcGIS Pro (13.1.0.41833)\nlicense: Advanced\nversion: 1.0.1.300 \n\n\nIf the function runs successfully, then the connection to ArcGIS has been initialized and licensing has been established. We can additionally check the license by storing arc.check_product() in a variable and calling $license on it.\n\ninfo &lt;- arc.check_product()\n\ninfo$license\n\n[1] \"Advanced\""
  },
  {
    "objectID": "posts/Unbreaking-R-Arcpy/index.html#setting-environment-in-reticulate",
    "href": "posts/Unbreaking-R-Arcpy/index.html#setting-environment-in-reticulate",
    "title": "How to Un-Break R with Arcpy in ArcGIS Pro",
    "section": "Setting Environment in Reticulate",
    "text": "Setting Environment in Reticulate\nOnce a connection to ArcGIS has been initialized, we need to inform reticulate about which python executable it should be running. If you use ArcGIS Pro, you will need to clone the original environment in order to use arcpy functionality. Like the original, the clone is a conda environment that one should be able to access. There are two ways we can tell reticulate to use this cloned environment.\n\nSetting a Global Option\nThe first option is to set a global python interpreter inside of RStudio. This can be done quite easily through the Tools &gt; Global Options &gt; Python &gt; Select &gt; Conda settings. Once you’ve selected the right environment, your python scripts should run from the python executable in that environment.\n\n\nUsing use_condaenv()\nAnother way is to call the use_condaenv() function to establish the path to the python executable file.\n\nlibrary(reticulate)\n\nuse_condaenv(\"../conda/env/arcgispro-py3-clone/python.exe\",\n             required = TRUE)\n\n# The first argument is the path\n# The second argument ensures that you get an error if \n# that python.exe file doesn't exist\n\nYou can verify that you are using the right environment by running;\n\npy_config()"
  },
  {
    "objectID": "posts/Unbreaking-R-Arcpy/index.html#importing-arcpy",
    "href": "posts/Unbreaking-R-Arcpy/index.html#importing-arcpy",
    "title": "How to Un-Break R with Arcpy in ArcGIS Pro",
    "section": "Importing arcpy",
    "text": "Importing arcpy\nAfter initializing the license and setting the right environment, we should be able to successfully import the arcpy module.\n\ntry:\n  import arcpy\n  print(\"arcpy successfully imported\")\nexcept:\n  print(\"An exception occured. Import was unsuccessful\")"
  }
]